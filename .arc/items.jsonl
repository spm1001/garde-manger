{"id": "arc-cuDugi", "type": "outcome", "title": "Fix critical bugs from titans review", "brief": {"why": "Three bugs will cause crashes/corruption: FTS5 rebuild uses wrong trigger syntax, populate_raw_text calls wrong methods on adapters", "what": "1. Fix rebuild-fts trigger syntax to match database.py schema 2. Fix LocalMdSource.from_file call (needs base_path) 3. Fix BeadsSource.from_file (use parse_jsonl instead)", "done": "All three bugs fixed, tests pass, no TypeError/AttributeError on populate-raw-text"}, "status": "done", "order": 1, "created_at": "2026-01-31T20:50:49Z", "created_by": "spm1001", "done_at": "2026-01-31T20:57:27Z"}
{"id": "arc-daKige", "type": "outcome", "title": "Remove Turso from codebase", "brief": {"why": "Turso cloud sync is disabled, has FTS5 corruption issues, and adds complexity (libsql dependency, dual connection paths). All three reviewers flagged it as dead weight.", "what": "1. Remove libsql dependency from pyproject.toml 2. Remove Turso credential handling from database.py 3. Remove sync command from CLI 4. Simplify database.py to pure sqlite3 5. Update README to remove Turso references", "done": "No Turso/libsql code remains, tests pass with sqlite3 only, README reflects local-only architecture"}, "status": "done", "order": 2, "created_at": "2026-01-31T20:50:56Z", "created_by": "spm1001", "done_at": "2026-01-31T21:04:12Z"}
{"id": "arc-hubaru", "type": "outcome", "title": "Implement Adapter Protocol", "brief": {"why": "ADAPTER_AUDIT.md documents interface inconsistencies, no compile-time or runtime enforcement exists. New adapters must reverse-engineer expected contract from examples.", "what": "1. Create src/mem/adapters/protocol.py with @runtime_checkable Protocol 2. Define required properties: source_id, has_presummary, full_text(), metadata 3. Add isinstance checks or type hints throughout 4. Update adapters/__init__.py to export all adapters", "done": "Protocol defined, all 7 adapters typed, isinstance checks pass, __init__.py exports complete"}, "status": "open", "order": 3, "created_at": "2026-01-31T20:51:03Z", "created_by": "spm1001"}
{"id": "arc-fiLalu", "type": "outcome", "title": "Reduce CLI scan() code duplication", "brief": {"why": "scan() repeats same 30-50 line pattern 7 times for each source type. Adding new source types is tedious and error-prone.", "what": "1. Extract generic scan loop function accepting adapter iterator and formatting options 2. Refactor each source type to use common function 3. Verify all source types still work", "done": "scan() reduced from ~400 lines to ~150, new source type can be added in <20 lines"}, "status": "open", "order": 4, "created_at": "2026-01-31T20:51:10Z", "created_by": "spm1001"}
{"id": "arc-Bojoke", "type": "outcome", "title": "Fix extraction.py source type coverage", "brief": {"why": "get_source_content() raises ValueError for local_md, beads, and arc - breaks extraction for these source types", "what": "1. Add handlers for local_md, beads, arc in get_source_content() 2. Or refactor to use adapter.full_text() directly (cleaner)", "done": "mem process works for all 7 source types without ValueError"}, "status": "open", "order": 5, "created_at": "2026-01-31T20:51:16Z", "created_by": "spm1001"}
{"id": "arc-SiKoHa", "type": "outcome", "title": "Audit exception handlers", "brief": {"why": "Multiple except Exception: pass patterns hide real errors - schema init, migrations, token parsing, config loading all silently swallow failures", "what": "1. Grep for 'except Exception' and 'except:' 2. Replace bare catches with specific exceptions or add logging 3. Ensure errors surface appropriately (stderr or logs, not stdout)", "done": "No bare except Exception: pass remains, all error paths logged or handled specifically"}, "status": "open", "order": 6, "created_at": "2026-01-31T20:51:22Z", "created_by": "spm1001"}
{"id": "arc-foCiZo", "type": "outcome", "title": "Add arc adapter tests", "brief": {"why": "Arc adapter was added without tests - test_beads_adapter.py exists but no test_arc_adapter.py. Arc is the newer, presumably active adapter.", "what": "1. Create tests/test_arc_adapter.py 2. Test ArcSource parsing, discover_arc(), metadata properties 3. Test edge cases: missing fields, malformed dates", "done": "test_arc_adapter.py exists, all tests pass, coverage similar to beads adapter tests"}, "status": "open", "order": 7, "created_at": "2026-01-31T20:51:28Z", "created_by": "spm1001"}
{"id": "arc-VuVuna", "type": "outcome", "title": "Review and update glossary", "brief": {"why": "Glossary has ITV org structure, products, and concepts but hasn't been audited for completeness or accuracy. Core to search experience.", "what": "1. Review ~/.claude/memory/glossary.yaml for stale entries 2. Add missing aliases discovered through use 3. Check parent relationships are correct 4. Add any missing common terms", "done": "Glossary reviewed, stale entries removed/updated, common aliases added, parent hierarchy verified"}, "status": "open", "order": 8, "created_at": "2026-01-31T20:51:34Z", "created_by": "spm1001"}
{"id": "arc-deloke", "type": "outcome", "title": "Document architectural decisions", "brief": {"why": "Key design decisions scattered or missing: Why standalone FTS5? Why no vector embeddings? Change detection semantics differ per adapter. No ADRs.", "what": "1. Create docs/ARCHITECTURE.md or ADR directory 2. Document FTS5 mode choice and rationale 3. Document change detection patterns per adapter 4. Capture why text search over summaries chosen over embeddings", "done": "Architecture decisions documented, future Claude can understand why choices were made"}, "status": "open", "order": 9, "created_at": "2026-01-31T20:51:41Z", "created_by": "spm1001"}
{"id": "arc-heboma", "type": "outcome", "title": "Address tech debt from titans review", "brief": {"why": "Lower priority items from code review: duplicated code, missing utilities, polish items that don't block shipping but should be tracked", "what": "1. Extract JSON parsing helper in llm.py 2. Unify parse_datetime across adapters 3. Define constants for magic numbers 4. Add DictRow.get() method 5. Standardize test import paths", "done": "Duplicated code extracted to utilities, magic numbers named, test imports consistent"}, "status": "open", "order": 10, "created_at": "2026-01-31T20:51:48Z", "created_by": "spm1001"}
{"id": "arc-peZeZu", "type": "outcome", "title": "Implement semantic chunking for extraction", "brief": {"why": "Fixed-size 140K chunks split mid-thought. Topic-aware splitting (timestamp gaps, speaker shifts, tool boundaries) would produce coherent chunks for better extraction quality.", "what": "Replace _split_with_overlap with _split_semantic. Detect topic boundaries. Variable chunk sizes based on content structure.", "done": "Chunking splits at topic boundaries, tests pass, merge produces coherent output"}, "status": "done", "order": 11, "created_at": "2026-02-01T08:15:02Z", "created_by": "spm1001", "done_at": "2026-02-01T09:33:45Z"}
{"id": "arc-Natura", "type": "outcome", "title": "Add typed learnings (W/B/O/S) to extraction", "brief": {"why": "OpenClaw pattern: tag learnings as World facts, Biographical, Opinion (with confidence), Summary. Enables filtering like 'mem search --type opinion' and finding TIL candidates.", "what": "Add learning_type field to extractions schema. Update hybrid prompt to output typed learnings.", "done": "Extractions have typed learnings, can filter by type in search"}, "status": "open", "order": 12, "created_at": "2026-02-01T08:15:09Z", "created_by": "spm1001"}
{"id": "arc-bivivu", "type": "outcome", "title": "Add tests for chunking code path", "brief": {"why": "Complex logic (split → extract N chunks → merge) has no test coverage. First real large session might produce weird output.", "what": "Test _split_with_overlap, _extract_chunk, _merge_chunk_results. Mock LLM calls.", "done": "Chunking functions have unit tests, edge cases covered"}, "status": "open", "order": 13, "created_at": "2026-02-01T08:15:15Z", "created_by": "spm1001"}
{"id": "arc-ruKolo", "type": "outcome", "title": "Add --verbose flag to show chunk boundaries", "brief": {"why": "When processing large sessions, no visibility into where semantic chunking splits content. Makes debugging and validation difficult.", "what": "Add verbose output to extract_hybrid() and CLI showing: chunk count, boundary indices, chunk sizes. Consider structured logging.", "done": "Running 'mem process --verbose' shows chunk boundaries with character positions"}, "status": "open", "order": 14, "created_at": "2026-02-01T09:33:55Z", "created_by": "spm1001"}
{"id": "arc-tobeta", "type": "outcome", "title": "Manual verification of semantic chunking", "brief": {"why": "Code works in tests but never validated against real multi-topic session. Need confidence boundaries align with human perception.", "what": "Find a session with 3+ obvious topic shifts. Process with verbose. Compare detected boundaries to actual topic changes.", "done": "One real session verified, boundaries match human-perceived topic shifts"}, "status": "open", "order": 15, "created_at": "2026-02-01T09:33:56Z", "created_by": "spm1001"}
